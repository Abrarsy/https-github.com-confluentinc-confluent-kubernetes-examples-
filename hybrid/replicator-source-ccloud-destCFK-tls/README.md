# Replicator

Confluent Replicator allows you to easily and reliably replicate topics from one Kafka cluster to another. In addition to copying the messages, Replicator will create topics as needed preserving the topic configuration in the source cluster. This includes preserving the number of partitions, the replication factor, and any configuration overrides specified for individual topics. Replicator is implemented as a connector.

In this scenario example, you'll deploy two Confluent clusters. One is the source cluster, and one is the destination cluster. You'll deploy Confluent Replicator on the destination cluster, where it will copy topic messages from the source cluster and write to the destination cluster.

Note: You can deploy Replicator near the destination cluster or the source cluster, and it will work either way. However, a best practice is to deploy Replicator closer to the destination cluster for reliability and performance over networks.

This scenario example document describes how to configure and deploy Confluent Replicator in one configuration scenario through Confluent for Kubernetes. To read more about the use cases, architectures and various configuration scenarios, please see the [Confluent Replicator documentation](https://docs.confluent.io/platform/current/multi-dc-deployments/replicator/index.html#replicator-detail).

## Set up Pre-requisites

Set the tutorial directory for this tutorial under the directory you downloaded
the tutorial files:

```
export TUTORIAL_HOME=<Tutorial directory>/hybrid/replicator-source-ccloud-destCFK-tls
```

Create namespace,  for the destination cluster.

```
kubectl create ns destination
```

Deploy Confluent for Kubernetes (CFK) in cluster mode, so that the one CFK instance can manage Confluent deployments in multiple namespaces. Here, CFk is deployed to the `default` namespace.

```
helm upgrade --install confluent-operator \
  confluentinc/confluent-for-kubernetes \
  --namespace destination
```

Confluent For Kubernetes provides auto-generated certificates for Confluent Platform components to use for inter-component TLS. You'll need to generate and provide a Root Certificate Authority (CA).

Generate a CA pair to use in this tutorial:

```
create from scratch so we can append the ccloud certs ? or we can just skip the entry in the payload
```

## Deploy source and destination clusters, including Replicator

Deploy destination cluster.

```
# Specify the credentials required by the source and destination cluster. To understand how these
# credentials are configured, see 
# https://github.com/confluentinc/confluent-kubernetes-examples/tree/master/security/secure-authn-encrypt-deploy

::


kubectl create secret generic kafka-tls \
  --from-file=fullchain.pem=$TUTORIAL_HOME/../../assets/certs/generated/server.pem \
  --from-file=cacerts.pem=$TUTORIAL_HOME/../../assets/certs/generated/ca.pem \
  --from-file=privkey.pem=$TUTORIAL_HOME/../../assets/certs/generated/server-key.pem \
  --namespace destination

::


:: 

  kubectl create secret generic cloud-plain \
  --from-file=plain.txt=$TUTORIAL_HOME/creds-client-kafka-sasl-user.txt \
  --namespace destination

::
kubectl apply -f $TUTORIAL_HOME/components-destination.yaml
kubectl apply -f $TUTORIAL_HOME/controlcenter.yaml
```

In `$TUTORIAL_HOME/components-destination.yaml`, note that the `Connect` CRD is used to define a 
custom resource for Confluent Replicator.

```
From $TUTORIAL_HOME/components-destination.yaml
---
apiVersion: platform.confluent.io/v1beta1
# Confluent Replicator is built as a connector, and so will use the `Connect` CRD.
kind: Connect
metadata:
  name: replicator
  namespace: destination
spec:
  replicas: 2
  # Configure to have TLS encryption, and use auto-generated server certs
  tls:
    autoGeneratedCerts: true
  image:
    # Use the `cp-enterprise-replicator-operator` Docker image, that contains the Replicator jars
    application: confluentinc/cp-enterprise-replicator-operator:6.1.1.0
    init: confluentinc/cp-init-container-operator:6.1.1.0
  podTemplate:
    resources:
      requests:
        cpu: 2
        memory: 4Gi
    envVars:
      # The  Confluent Replicator Monitoring Extension allows for detailed metrics from Replicator tasks to be 
      # collected using an exposed REST API.
      # You'll need to update the version string in replicate-test-extension-<version>.jar based on what 
      # CP version you are using
      - name: CLASSPATH
        value: /usr/share/java/kafka-connect-replicator/replicator-rest-extension-6.1.1.jar
  configOverrides:
    # When the Connect distributed cluster hosting Replicator has a REST endpoint with SSL encryption 
    # enabled, you must configure security properties for the SSL keystore and truststore used by the 
    # Replicator monitoring extension to communicate with other Connect nodes in the cluster.
    # `/mnt/sslcerts/kafka-tls/truststore.p12` is the truststore location when auto-genarated certs are used.
    jvm:
      - -Djavax.net.ssl.trustStore=/mnt/sslcerts/kafka-tls/truststore.p12
      - -Djavax.net.ssl.trustStorePassword=mystorepassword
    server:
      # To activate the monitoring extension, configure this property
      - rest.extension.classes=io.confluent.connect.replicator.monitoring.ReplicatorMonitoringExtension
      # This specifies that Replicator is the Connector configured
      - connector.class=io.confluent.connect.replicator.ReplicatorSourceConnector
  dependencies:
    kafka:
      bootstrapEndpoint: kafka.destination.svc.cluster.local:9071
      authentication:
        type: plain
        jaasConfig:
          secretRef: credential
      tls:
        enabled: true
    interceptor:
      enabled: true
---
```

## Create topic in source cluster

```
# This uses the `kafkaTopic` CRD to define a topic
kubectl apply -f $TUTORIAL_HOME/source-topic.yaml
```




```
 kafka-topics --bootstrap-server <ccloud-endpoint:9092> \
--command-config  ~/kafkaexample/ccloud-team/client.properties \
--create \
--partitions 3 \
--replication-factor 3 \
--topic moshe-topic-in-source
```


Create messages  


```
seq 1000  | kafka-console-producer --broker-list  <ccloud-endpoint:9092> \
--producer.config  ~/kafkaexample/ccloud-team/client.properties \
--topic moshe-topic-in-source
```




## Configure Replicator in destination cluster

Confluent Replicator requires the configuration to be provided as a file in the running Docker container.
You'll then interact with it through the REST API, to set the configuration.

```
# SSH into the `replicator-0` pod
kubectl -n destination exec -it replicator-0 -- bash

# Define the configuration as a file in the pod
cat <<EOF > replicator.json
 {
 "name": "replicator",
 "config": {
     "connector.class":  "io.confluent.connect.replicator.ReplicatorSourceConnector",
     "src.kafka.sasl.jaas.config": "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"<ccloud-key>\" password=\"<ccloud-pass>\";",
     "confluent.license": "",
     "confluent.topic.replication.factor": "3",
     "confluent.topic.security.protocol": "SSL",
     "confluent.topic.ssl.truststore.location":"/mnt/sslcerts/kafka-tls/truststore.p12",
     "confluent.topic.ssl.truststore.password":"mystorepassword",
     "confluent.topic.ssl.truststore.type": "PKCS12",
     "dest.kafka.bootstrap.servers": "kafka.destination.svc.cluster.local:9071",
     "dest.kafka.security.protocol": "SSL",
     "dest.kafka.ssl.keystore.type": "PKCS12",
     "dest.kafka.ssl.truststore.location": "/mnt/sslcerts/kafka-tls/truststore.p12",
     "dest.kafka.ssl.truststore.password": "mystorepassword",
     "dest.kafka.ssl.truststore.type": "PKCS12",
     "key.converter": "io.confluent.connect.replicator.util.ByteArrayConverter",
     "src.kafka.bootstrap.servers": "<ccloud-endpoint:9092>",
     "src.kafka.sasl.mechanism": "PLAIN",
     "src.kafka.security.protocol": "SASL_SSL",
     "src.kafka.ssl.keystore.type": "PKCS12",
     "src.kafka.ssl.truststore.location": "/mnt/sslcerts/kafka-tls/truststore.p12",
     "src.kafka.ssl.truststore.password": "mystorepassword",
     "src.kafka.ssl.truststore.type": "PKCS12",
     "tasks.max": "4",
     "topic.whitelist": "moshe-topic-in-source",
      "topic.rename.format": "\${topic}_replica",
     "value.converter": "io.confluent.connect.replicator.util.ByteArrayConverter"
   }
 }
EOF

# Instantiate the Replicator Connector instance through the REST interface
curl -XPOST -H "Content-Type: application/json" --data @replicator.json https://localhost:8083/connectors -k

# Check the status of the Replicator Connector instance
curl -XGET -H "Content-Type: application/json" https://localhost:8083/connectors -k

curl -XGET -H "Content-Type: application/json" https://localhost:8083/connectors/replicator/status -k

```

To delete: 

```
curl -XDELETE -H "Content-Type: application/json" https://localhost:8083/connectors/replicator -k
```

## Validate that it works

### Produce data to topic in source cluster

Create the kafka.properties file in $TUTORIAL_HOME. Add the above endpoint and the credentials as follows:

```
bootstrap.servers=kafka.source.svc.cluster.local:9071
sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=kafka password=kafka-secret;
sasl.mechanism=PLAIN
security.protocol=SASL_SSL
ssl.truststore.location=/mnt/sslcerts/kafka-tls/truststore.p12
ssl.truststore.password=mystorepassword

# Create a configuration secret for client applications to use
kubectl create secret generic kafka-client-config-secure \
  --from-file=$TUTORIAL_HOME/kafka.properties -n source
```

Deploy a producer application that produces messages to the topic `topic-in-source`:

```
kubectl apply -f $TUTORIAL_HOME/secure-producer-app-data.yaml
```

### View in Control Center

Open Confluent Control Center.

```
kubectl confluent dashboard controlcenter -n destination
```